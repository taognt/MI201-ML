{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# <font size = \"6\"> **Projet Pizzo Topping - Morel, Guinot et Mssellati**\n","\n","Dans ce projet nous allons tenter de prédire les toppings sur des images de pizza. Nous nous sommes concentré sur la base des pizzas générées artificiellement. \n","\n","Nous avons tenté et adapté notre approche au fur et à mesure du projet. \n","Nous vous les présentons dans un ordre à complexité croissante. \n"],"metadata":{"id":"OvvEuMMMWvRB"}},{"cell_type":"code","source":["##Bibliotheque utiles dans tous le notebook\n","import pandas as pd\n","import numpy as np\n","import os\n","import time\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","from tqdm import tqdm\n","\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","\n","#import shutil\n","\n","import sys\n","if not sys.warnoptions:\n","    import warnings\n","    warnings.simplefilter(\"ignore\")\n","\n","# scikitlearn\n","from sklearn.metrics import confusion_matrix, classification_report, f1_score, ConfusionMatrixDisplay, multilabel_confusion_matrix\n","from sklearn.model_selection import train_test_split\n","\n","# Pytorch\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import models\n","from torch.optim import lr_scheduler\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","#!pip install torchmetrics\n","#from torchmetrics.classification import MultilabelF1Score, MultilabelAccuracy\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","if (torch.cuda.is_available()):\n","  !nvidia-smi"],"metadata":{"id":"XkpiLHDKdXYf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## <font size = \"7\"> CNN simple </font>\n","\n","\n","\n"],"metadata":{"id":"zHMmrC6_XsQi"}},{"cell_type":"markdown","source":["## <font size = \"7\"> Feature extraction\n","\n","Dans cette partie nous allons étudier l'efficacité de différentes méthodes d'apprentissage en sortit d'un réseau de neurones pre entrainé. \n","\n","La première approche a été de classifier la sortie de ResNet avec des méthodes de classification supervisé vues en cours.\n","\n","La deuxième consiste à entraîner un MLP avec la sortie d'un CNN déjà entrainé. \n","\n","Noter qu'ici nous ne touchons en rien aux poids du réseau initial, seule la sortie est traitée."],"metadata":{"id":"5IgAWpM7X2mq"}},{"cell_type":"markdown","source":["### <font size = \"6\"> ResNext + Classifier\n","\n","Un Resnet est un réseau qui va interconnecter des neurones jusqu'à plus d'une couche. Il est composé de bloc résiduel les uns à la suite des autres. Cela permet de réduire l'explosion ou la chute du gradient durant l'optimisation. Ce phénomène apparaît lorsqu'il y a beaucoup de couches. Nous avons donc suivi dans un premier temps les indications du sujet et traité la sortie du Resnet. En particulier, c'est un ResNext 50 qui est utilisé, utilisant également à de l'inception et de la profondeur.\n","\n","Dans cette partie, nous allons tester différentes méthodes de classification en sortie du ResNext. ResNext reste assez simple et léger pour évaluer l'ensemble du data set."],"metadata":{"id":"fdwGD_OgYJGt"}},{"cell_type":"code","source":["#Bliotheque necessaire à la classification \n","from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import Perceptron\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay"],"metadata":{"id":"1mTvdyanIw-m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def True_ratio(y_val,y_val_pred):\n","  ratio_list=[]\n","  for i in range(y_val.shape[1]): \n","    nb_of_true_overall=0\n","    nb_of_true=0\n","    ratio=0\n","    for j in range(y_val.shape[0]) :\n","      if y_val[j,i]==1 :\n","        nb_of_true_overall=nb_of_true_overall+1\n","        if y_val_pred[j,i]==y_val[j,i] :\n","          nb_of_true=nb_of_true+1\n","    if nb_of_true_overall!=0 :\n","      ratio=nb_of_true/nb_of_true_overall\n","      ratio_list.append(ratio)\n","  return ratio_list"],"metadata":{"id":"4FznbrWCMBb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_val, y_train, y_val = train_test_split(feat_double, y_all_double, test_size=0.2, random_state=123)"],"metadata":{"id":"EbM5VXSJHPPy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### SVM\n","Ici, nous testons un SVM lineair.\n","\n","Dans cette partie et dans la suite, il est important de préciser à SKLearn que les outputs sont multiples."],"metadata":{"id":"6_vPYLIBY1v5"}},{"cell_type":"code","source":["multiclass_SVM = MultiOutputClassifier(LinearSVC(random_state=42, C=2))"],"metadata":{"id":"pIM-PenVHgMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Training\n","multiclass_SVM= multiclass_SVM.fit(X_train, y_train)"],"metadata":{"id":"2KPea8klJoh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Predict \n","y_val_pred = multiclass_SVM.predict(X_val)"],"metadata":{"id":"nGrp9WGUPusR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ici se pose la question de la représentions de l'efficacité des classifieurs.\n"," \n","Nous avons d'abord pensé à des matrices de confusion pour chacune des classes. "],"metadata":{"id":"C-auHicrQFsk"}},{"cell_type":"code","source":["# Confusion Matrix multiclass\n","matrices = multilabel_confusion_matrix(y_val, y_val_pred)\n","nlabels = 10\n","for k in range(nlabels):\n","  cmd = ConfusionMatrixDisplay(matrices[k], display_labels=np.unique(y_test)).plot()\n","  plt.title('Confusion Matrix for label {}'.format(k+1))\n","  plt.show()"],"metadata":{"id":"o2H1ffkBQFJK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Il est assez compliqué d'interpréter les résultats. \n","\n","En effet, dans la majorité des cas, pour un topping donné, il ne sera pas là. C'est la raison pour laquelle le cadrant en haut à gauche est rempli.\n","De plus, il est assez difficile de voir autant de matrice d'un coup. \n","Les matrices ne sont pas forcément adaptées à l'analyse de méthodes pour notre problème. \n","\n","Nous nous sommes dirigés naturellement vers un pourcentage réussite par classe. "],"metadata":{"id":"WLFZt6GCQ9LP"}},{"cell_type":"code","source":["# Bar charts for average predictios\n","perf_label_val = np.zeros(nlabels)\n","for k in range(len(y_val_pred)):\n","  perf_label_val = perf_label_val + (y_val[k] == y_val_pred[k])\n","\n","res = perf_label_val/y_val_pred.shape[0]*100\n","\n","print(res)\n","\n","plt.figure()\n","plt.bar(np.linspace(0,10,10), perf_label_val/y_val_pred.shape[0]*100)"],"metadata":{"id":"tNZV24xSSYjS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ici, les scores peuvent paraitre bons. Mais comme souligne déjà plus, ce que nous voulons principalement, c'est savoir : pour un topping donné, quand est-ce que le modèle a bien prédit. \n","\n","Nous avons donc mis en place cette métrique : True_ratio. \n","Elle peut paraitre trop forte de prime abord, mais elle a le mérite de briller lorsque les résultats sont convaincants."],"metadata":{"id":"kZOL7oSbSjF7"}},{"cell_type":"code","source":["# Bar charts for when true predictions\n","Ratios_SVM = True_ratio(y_val,y_val_pred)\n","print(Ratios_SVM)\n","plt.figure()\n","plt.bar(np.linspace(0,10,10),Ratios_SVM)\n","print('Overall : ', np.array(Ratios_SVM).mean() ) # moyenne des scores"],"metadata":{"id":"fgCGOSqLQB_n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nous pouvons donc voir ici que le SVM ne produit pas des scores très élevés.\n","\n","Nous avions également testé un SVM non linéaire, mais le temps d'entrainement et de prédiction était bien trop élevé pour un score trop bas. "],"metadata":{"id":"bVZ5Md5qTgZp"}},{"cell_type":"markdown","source":["#### KNN \n","\n","Nous essayons egalment les K voisins :"],"metadata":{"id":"746j89EdZZ1W"}},{"cell_type":"code","source":["multiclass_KNN = MultiOutputClassifier(KNeighborsClassifier(n_neighbors=7, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n","                             metric='minkowski', metric_params=None, n_jobs=None))"],"metadata":{"id":"3YH6dYRsUkDq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Apres quelques tests, 7 est un bon compromis perfomance resultats"],"metadata":{"id":"89w7Gf8wVCEo"}},{"cell_type":"code","source":["#Predict (no training for Knn)\n","y_val_pred = multiclass_KNN.predict(X_val)"],"metadata":{"id":"qFkXkpNmUkDr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bar charts for when true predictions\n","Ratios_knn = True_ratio(y_val,y_val_pred)\n","print(Ratios_knn)\n","plt.figure()\n","plt.bar(np.linspace(0,10,10),Ratios_knn)\n","print('Overall : ', np.array(Ratios_knn).mean() ) # moyenne des scores"],"metadata":{"id":"J-TwgIO5UkDr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Random Forest\n","\n"],"metadata":{"id":"8JeJP8PzaEXO"}},{"cell_type":"code","source":["multiclass_RandomFor = MultiOutputClassifier(RandomForestClassifier(n_estimators=50, criterion='gini', max_depth=None,\n","                               min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n","                               max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, \n","                               oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, \n","                               ccp_alpha=0.0, max_samples=None))\n"],"metadata":{"id":"KIcP1Kmdey9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Training\n","multiclass_RandomFor = multiclass_RandomFor.fit(X_train, y_train)"],"metadata":{"id":"pSCReGC-fAgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Predict \n","y_val_pred = multiclass_RandomFor.predict(X_val)"],"metadata":{"id":"42p9-lo4fAgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bar charts for when true predictions\n","Ratios_for = True_ratio(y_val,y_val_pred)\n","print(Ratios_for)\n","plt.figure()\n","plt.bar(np.linspace(0,10,10),Ratios_for)\n","print('Overall : ', np.array(Ratios_for).mean() ) # moyenne des scores"],"metadata":{"id":"Ypon9KZ9fAgc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comme on peut le voir Random forrest ne fournit pas des resultats satisfaisant."],"metadata":{"id":"8_AJPE4_fURy"}},{"cell_type":"markdown","source":["#### Perceptron"],"metadata":{"id":"Gi1hizDwamuo"}},{"cell_type":"code","source":["multiclass_Perceptron = MultiOutputClassifier(Perceptron(penalty = 'elasticnet',verbose=1))\n"],"metadata":{"id":"041qtsBFf1XR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Apres quelques tests, elasticnet avait l'air de fonctionner le mieux ."],"metadata":{"id":"Jtdd4-ucgdU0"}},{"cell_type":"code","source":["multiclass_Perceptron = multiclass_Perceptron.fit(X_train, y_train)"],"metadata":{"id":"2U_BD2v7f1XS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Predict \n","y_val_pred = multiclass_Perceptron.predict(X_val)"],"metadata":{"id":"oQX6Gh6rf1XS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bar charts for when true predictions\n","Ratios_Per = True_ratio(y_val,y_val_pred)\n","print(Ratios_Per)\n","plt.figure()\n","plt.bar(np.linspace(0,10,10),Ratios_Per)\n","print('Overall : ', np.array(Ratios_Per).mean() ) # moyenne des scores"],"metadata":{"id":"-NH3q-Y4f1XS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Le perceptron fournis des résultats convaincant par rapport à d'autre classifieur. C'est un équivalent à un MLP à une couche. Ce qui nous a poussé à greffer un MLP un peu plus développé à la sortie du réseau pré entrainé sur des images. "],"metadata":{"id":"P__jj79OfpGE"}},{"cell_type":"markdown","source":["### <font size = \"6\"> Pre-trained CNN + MLP\n"],"metadata":{"id":"NN4-SqPqYJsE"}},{"cell_type":"markdown","source":["#### ResNet + MLP"],"metadata":{"id":"c--teqHka06x"}},{"cell_type":"markdown","source":["#### VGG + MLP"],"metadata":{"id":"3P3khYDWa5jC"}},{"cell_type":"markdown","source":["#### AlexNet + MLP"],"metadata":{"id":"mD0uegWqa8JV"}},{"cell_type":"markdown","source":["## <font size = \"7\"> Fine Tuning\n","\n"],"metadata":{"id":"8oLNWhbGY4kB"}},{"cell_type":"markdown","source":["## <font size = \"6\"> **Conclusion**\n","\n"],"metadata":{"id":"Yl8JSqNTZIRP"}}]}